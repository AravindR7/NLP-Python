{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSummarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpdVovfxDutlD7oHcHHXV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AravindR7/NLP-Python/blob/master/TextSummarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6i2lk-po79Q",
        "colab_type": "text"
      },
      "source": [
        "# Text Summarization\n",
        "\n",
        "  The process of distilling the most important information from a source text.\n",
        "Summaries reduce reading time. Automatic text summarization improves effectiveness of indexing.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eky5DEI3pgd5",
        "colab_type": "text"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a6PCgEX0RG3",
        "colab_type": "code",
        "outputId": "3f670818-69e5-41ca-a84f-5e8e92dace48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Load Dataset\n",
        "!wget https://raw.githubusercontent.com/Jcharis/Natural-Language-Processing-Tutorials/NLP_Tutorials/Automatic_Text_Summarization_with_Python/example.txt"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 17:22:59--  https://raw.githubusercontent.com/Jcharis/Natural-Language-Processing-Tutorials/NLP_Tutorials/Automatic_Text_Summarization_with_Python/example.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2484 (2.4K) [text/plain]\n",
            "Saving to: ‘example.txt.3’\n",
            "\n",
            "\rexample.txt.3         0%[                    ]       0  --.-KB/s               \rexample.txt.3       100%[===================>]   2.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-08 17:23:00 (54.9 MB/s) - ‘example.txt.3’ saved [2484/2484]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEGxfQ4mEWhm",
        "colab_type": "text"
      },
      "source": [
        "We will not be working on building our own text summarization pipeline, but rather focus on using built-in summarization API which Gensim offers us.\n",
        "\n",
        "The summarization is based on TextRank algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXo2AaRVxWz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "de1089d4-8cf8-44ad-a17c-2879a15fa6c0"
      },
      "source": [
        "!pip3 install gensim\n",
        "!pip3 install gensim_sum_ext"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.13.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.16.19)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: gensim_sum_ext in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from gensim_sum_ext) (3.6.0)\n",
            "Requirement already satisfied: pycorenlp in /usr/local/lib/python3.6/dist-packages (from gensim_sum_ext) (0.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->gensim_sum_ext) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->gensim_sum_ext) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->gensim_sum_ext) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim->gensim_sum_ext) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pycorenlp->gensim_sum_ext) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->gensim_sum_ext) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->gensim_sum_ext) (1.13.19)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp->gensim_sum_ext) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp->gensim_sum_ext) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp->gensim_sum_ext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp->gensim_sum_ext) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->gensim_sum_ext) (1.16.19)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->gensim_sum_ext) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->gensim_sum_ext) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim->gensim_sum_ext) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.2.1->gensim->gensim_sum_ext) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Zs1KDTp17o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.summarization import summarize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ngX7cxzu74D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mytext = \"\"\"\n",
        "Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax.\n",
        "\n",
        "Automatic data summarization is part of machine learning and data mining. The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set. Such techniques are widely used in industry today. Search engines are an example; others include summarization of documents, image collections and videos. Document summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.\n",
        "For surveillance videos, one might want to extract the important events from the uneventful context.\n",
        "\n",
        "There are two general approaches to automatic summarization: extraction and abstraction. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Such a summary might include verbal innovations. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZF13CM1b8A",
        "colab_type": "code",
        "outputId": "f20bf5d0-dc2e-4e41-f3b8-2e74a6c1d46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "summarize(mytext)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.\\nDocument summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJm9nhZX5Jp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_text = summarize(mytext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V3Xtau96Z5L",
        "colab_type": "code",
        "outputId": "8afd8c87-7fba-405e-89f4-d069b09b673b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(summary_text)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFtv9bBo6cry",
        "colab_type": "code",
        "outputId": "d48bd3fe-ba5d-4129-bd43-05877c561ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# to set amount you want as summary\n",
        "summarize(mytext, ratio=0.2)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.\\nDocument summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5uqmdtv6qmq",
        "colab_type": "code",
        "outputId": "56eaff98-230c-4d0e-c903-bc065ea3b90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "summarize(mytext, word_count=50)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Automatic summarization is the process of shortening a text document with software, in order to create a summary with the major points of the original document.\\nDocument summarization tries to create a representative summary or abstract of the entire document, by finding the most informative sentences, while in image summarization the system finds the most representative and important (i.e. salient) images.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHQh6z26ufZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_text2 = summarize(mytext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqT3wiU16wvR",
        "colab_type": "code",
        "outputId": "283298ad-811e-4fd1-8996-a9d06e47adeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Number of words \n",
        "len(summary_text2)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFIW2yeh6y3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docx = open(\"/content/example.txt\").read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhd4GPbO660V",
        "colab_type": "code",
        "outputId": "2f2b34d9-593e-489c-ccdf-49b1f084eb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "docx"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The nativity of Jesus or birth of Jesus is described in the gospels of Luke and Matthew. The two accounts agree that Jesus was born in Bethlehem in the time of Herod the Great, that his mother Mary was married to Joseph, who was of Davidic descent and was not his biological father, and that his birth was effected by divine intervention, but the two gospels agree on little else.[1] Matthew does not mention the census, annunciation to the shepherds or presentation in the Temple, and does not give the name of the angel that appeared to Joseph to foretell the birth. In Luke there is no mention of Magi, no flight into Egypt, or Massacre of the Innocents, and the angel who announces the coming birth to Mary is named (as Gabriel).[1]\\n\\nThe consensus of scholars is that both gospels were written about AD 75-85,[2] and while it is possible that one account might be based on the other, or that the two share common source material, the majority conclusion is that, in respect of the nativity story, the two are independent of each other.[1]\\n\\nIn Christian theology the nativity marks the birth of Jesus in fulfillment of the divine will of God, to save the world from sin. The artistic depiction of the nativity has been an important subject for Christian artists since the 4th century. Since the 13th century, the nativity scene has emphasized the humility of Jesus and promoted a more tender image of him, as a major turning point from the early \"Lord and Master\" image, mirroring changes in the common approaches taken by Christian pastoral ministry.[3][4][5]\\n\\nThe nativity plays a major role in the Christian liturgical year. Christian congregations of the Western tradition (including the Catholic Church, the Western Rite Orthodox, the Anglican Communion, and many Protestants) begin observing the season of Advent four Sundays before Christmas, the traditional feast-day of his birth, which falls on December 25.\\n\\nChristians of the Eastern Orthodox Church and Oriental Orthodox Church observe a similar season, sometimes called Advent but also called the \"Nativity Fast\", which begins forty days before Christmas. Some Eastern Orthodox Christians (e.g. Greeks and Syrians) celebrate Christmas on December 25. Other Orthodox (e.g. Copts, Ethiopians, Georgians, and Russians) celebrate Christmas on (the Gregorian) January 7 (Koiak 29 on coptic calendar)[6] as a result of their churches continuing to follow the Julian calendar, rather than the modern day Gregorian calendar.\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lyIWhSxJsqX",
        "colab_type": "text"
      },
      "source": [
        " You can adjust how much text the summarizer outputs via the “ratio” parameter or the “word_count” parameter. Using the “ratio” parameter, you specify what fraction of sentences in the original text should be returned as output. Below we specify that we want 10% of the original text (the default is 20%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNeE10o0624p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mysummary = summarize(docx, ratio=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmnh1mmc63gS",
        "colab_type": "code",
        "outputId": "70458a99-57b2-41ec-ac4d-524fe6051ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mysummary"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Christian congregations of the Western tradition (including the Catholic Church, the Western Rite Orthodox, the Anglican Communion, and many Protestants) begin observing the season of Advent four Sundays before Christmas, the traditional feast-day of his birth, which falls on December 25.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdbpKYS6_Rp",
        "colab_type": "code",
        "outputId": "1756db5a-95f2-4e35-c230-d54f9cb36403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mysummary in docx"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuO318Zs9gXD",
        "colab_type": "code",
        "outputId": "7e1d5c57-4c06-4d1a-e974-bb4d3adcba69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "docx.find(mysummary)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJJoYgGY9meq",
        "colab_type": "code",
        "outputId": "89f3f451-d1ea-4abc-adee-2d434a469e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "docx[1631:]"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Christian congregations of the Western tradition (including the Catholic Church, the Western Rite Orthodox, the Anglican Communion, and many Protestants) begin observing the season of Advent four Sundays before Christmas, the traditional feast-day of his birth, which falls on December 25.\\n\\nChristians of the Eastern Orthodox Church and Oriental Orthodox Church observe a similar season, sometimes called Advent but also called the \"Nativity Fast\", which begins forty days before Christmas. Some Eastern Orthodox Christians (e.g. Greeks and Syrians) celebrate Christmas on December 25. Other Orthodox (e.g. Copts, Ethiopians, Georgians, and Russians) celebrate Christmas on (the Gregorian) January 7 (Koiak 29 on coptic calendar)[6] as a result of their churches continuing to follow the Julian calendar, rather than the modern day Gregorian calendar.\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V8PX1qq9rAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.summarization.textcleaner import split_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRVKVUGG9yVa",
        "colab_type": "code",
        "outputId": "3dcfb189-4057-4803-f3e0-3850a694d011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "split_sentences(docx)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The nativity of Jesus or birth of Jesus is described in the gospels of Luke and Matthew.',\n",
              " 'The two accounts agree that Jesus was born in Bethlehem in the time of Herod the Great, that his mother Mary was married to Joseph, who was of Davidic descent and was not his biological father, and that his birth was effected by divine intervention, but the two gospels agree on little else.[1] Matthew does not mention the census, annunciation to the shepherds or presentation in the Temple, and does not give the name of the angel that appeared to Joseph to foretell the birth.',\n",
              " 'In Luke there is no mention of Magi, no flight into Egypt, or Massacre of the Innocents, and the angel who announces the coming birth to Mary is named (as Gabriel).[1]',\n",
              " 'The consensus of scholars is that both gospels were written about AD 75-85,[2] and while it is possible that one account might be based on the other, or that the two share common source material, the majority conclusion is that, in respect of the nativity story, the two are independent of each other.[1]',\n",
              " 'In Christian theology the nativity marks the birth of Jesus in fulfillment of the divine will of God, to save the world from sin.',\n",
              " 'The artistic depiction of the nativity has been an important subject for Christian artists since the 4th century.',\n",
              " 'Since the 13th century, the nativity scene has emphasized the humility of Jesus and promoted a more tender image of him, as a major turning point from the early \"Lord and Master\" image, mirroring changes in the common approaches taken by Christian pastoral ministry.[3][4][5]',\n",
              " 'The nativity plays a major role in the Christian liturgical year.',\n",
              " 'Christian congregations of the Western tradition (including the Catholic Church, the Western Rite Orthodox, the Anglican Communion, and many Protestants) begin observing the season of Advent four Sundays before Christmas, the traditional feast-day of his birth, which falls on December 25.',\n",
              " 'Christians of the Eastern Orthodox Church and Oriental Orthodox Church observe a similar season, sometimes called Advent but also called the \"Nativity Fast\", which begins forty days before Christmas.',\n",
              " 'Some Eastern Orthodox Christians (e.g. Greeks and Syrians) celebrate Christmas on December 25.',\n",
              " 'Other Orthodox (e.g. Copts, Ethiopians, Georgians, and Russians) celebrate Christmas on (the Gregorian) January 7 (Koiak 29 on coptic calendar)[6] as a result of their churches continuing to follow the Julian calendar, rather than the modern day Gregorian calendar.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIxeFj0891Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all sentences\n",
        "all_sentences = split_sentences(docx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpcorH-97Ey",
        "colab_type": "code",
        "outputId": "073967ab-aa65-48c0-94b8-b75fc6e3bc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mysummary in all_sentences"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uE-jha98i6",
        "colab_type": "code",
        "outputId": "909f97ce-c68d-48e9-a54d-4e782aaa3ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Index of summarized text\n",
        "all_sentences.index(mysummary)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YkAHQXV9-La",
        "colab_type": "code",
        "outputId": "1ce79ecc-6c87-4ed3-c4a4-72855f8847b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_sentences[8]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Christian congregations of the Western tradition (including the Catholic Church, the Western Rite Orthodox, the Anglican Communion, and many Protestants) begin observing the season of Advent four Sundays before Christmas, the traditional feast-day of his birth, which falls on December 25.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ4c_Imt6XBd",
        "colab_type": "text"
      },
      "source": [
        "# Text Summarization Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEUl3zc5L8-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ae363dfa-7573-4fcb-b598-34bce6ce9201"
      },
      "source": [
        "pip install keras-self-attention"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.46.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hVwtHar-AGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_self_attention import SeqSelfAttention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBbCL0zEF49N",
        "colab_type": "code",
        "outputId": "bdab1d4e-c066-4829-d66e-701482d544dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Import libraries\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-_iFTeziCQ",
        "colab_type": "text"
      },
      "source": [
        "# You can download the dataset from [here](https://www.kaggle.com/snap/amazon-fine-food-reviews)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEr5jt7G9PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the dataset\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Datasets/Reviews.csv\",nrows=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQmvojNTkwS2",
        "colab_type": "text"
      },
      "source": [
        "# Drop duplicates and NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSA6f47qHJMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'], inplace=True)  # dropping duplicates\n",
        "data.dropna(axis=0, inplace=True)  # dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvDaSUykk7_F",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKaGP83kHbxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHziIXKBu2FJ",
        "colab_type": "text"
      },
      "source": [
        "# Text cleaning\n",
        "Preprocessing tasks\n",
        "**bold text**\n",
        "\n",
        "\n",
        "1. Convert everything to lowercase\n",
        "2. Remove HTML tags\n",
        "3. Contraction mapping\n",
        "4. Remove('s)\n",
        "5. Remove any text inside paranthesis ()\n",
        "6. Eliminate punctuations and special characters\n",
        "7. Remove stopwords \n",
        "8. Remove shortwords\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC6Us1__uOoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))\n",
        "    cleaned_text.append(text_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znU5sHGXEWuS",
        "colab_type": "text"
      },
      "source": [
        "# Summary cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3tvecKoMMCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data['Summary'][:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR5HoewNE6de",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFcDftf2H1f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_'+ x + '_END_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dtl4509Jio4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "  print('Review:', data['cleaned_text'][i])\n",
        "  print(\"Summary\", data['cleaned_summary'][i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fG0qMqkNZYv",
        "colab_type": "text"
      },
      "source": [
        "# Understanding the distribution of sequenceces\n",
        "\n",
        "We analyse the length of reviews and summary to get an overall idea about the distribution of length of the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or9BwKPQNEJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the list with sequence lengths\n",
        "for i in data['cleaned_text']:\n",
        "  text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "  summary_word_count.append(len(i.split()))\n",
        "\n",
        "\n",
        "length_df = pd.DataFrame({'text': text_word_count, 'summary': summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_6SIUzpRxnt",
        "colab_type": "text"
      },
      "source": [
        "Looks interesting. We can fix maximum length of reviews to 80 since that seems to be majority review length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPNex35sRfw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text=80\n",
        "max_len_summary=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFBahCvUh7Y",
        "colab_type": "text"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJD8KXFpUVyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 90% of dataset as training data and evaluate the performance on remaining 10%\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(data['cleaned_text'], data['cleaned_summary'],test_size=0.1, random_state=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGXj6j3FbwT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvCAp2up3t_P",
        "colab_type": "text"
      },
      "source": [
        "# Model buuilding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a5tRLUR2T1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = SeqSelfAttention(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ltaUAZ8yVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_XhV9Qv_lzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLN2aYBRD7Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6M-eQymD8sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tYmvVCnERZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjFHlxEuES7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD605VTuEaYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMVDjI_QEwP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9O1qMmCExDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(x_val)):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwe-MJX4E3tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}